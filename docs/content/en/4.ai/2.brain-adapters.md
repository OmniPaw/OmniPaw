---
title: Brain Adapters
description: Technical guide to connecting LLMs to the OmniPaw kernel with strict determinism.
navigation:
  icon: i-lucide-brain-circuit
seo:
  title: OmniPaw - Brain Adapters
  description: Configuring OpenAI, Anthropic, and local models for the deterministic substrate.
---

# Brain Adapters

A **Brain Adapter** is the translation layer between a Large Language Model (LLM) and the OmniKernel. Its job is to map the probabilistic nature of AI onto the deterministic structure of the substrate.

## Common Adapters

OmniPaw provides native adapters for the leading AI providers, as well as support for local inference.

| Provider      | Adapter Type     | Primary Use Case                              |
| :------------ | :--------------- | :-------------------------------------------- |
| **OpenAI**    | `OpenAiBrain`    | General purpose coordination and speed.       |
| **Anthropic** | `AnthropicBrain` | Complex reasoning and large-scale tool usage. |
| **Ollama**    | `LocalBrain`     | Air-gapped, 100% private execution.           |

## Configuring for Determinism

To ensure the agent behaves predictably across re-runs, the adapter must be configured with **Temperature 0**.

```typescript
import { LlmBrainAdapter } from "@omnipaw/kernel/host";

const brain = new LlmBrainAdapter({
  provider: "anthropic",
  model: "claude-3-5-sonnet-latest",
  temperature: 0, // CRITICAL: Prevents logic drift during replays
  maxTokens: 4000,
});
```

::code-preview
:omni-config-preview
::

## Execution Lifecycle

When the brain initiates a "Thought Cycle", the adapter performs the following:

1.  **Context Assembly**: It reads the `AgentStore` and filters relevant [Contextual MCP](/en/ai/contextual-mcp) data.
2.  **Instruction Generation**: It asks the model for the next step (e.g., "Call the bash tool to list files").
3.  **Governance Check**: The kernel intercepts the generated instruction and verifies it against the [Security Invariants](/en/essentials/security-invariants).

## Multi-Model Strategy

In a [Swarm Intelligence](/en/ai/swarm-intelligence) setup, you can assign different brain adapters to different agents. A "Strategy Agent" might use a heavy model (Claude), while a "Worker Agent" might use a lightweight local model (Mistral).

Next: Explore [LLMs](/en/ai/llms).
